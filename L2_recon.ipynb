{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from model.net import *\n",
    "from utils.training import *\n",
    "from data.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd()\n",
    "\n",
    "args = {\n",
    "    'USE_CUDA': True if torch.cuda.is_available() else False,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'N_EPOCHS': 30,\n",
    "    'LEARNING_RATE': 0.01,\n",
    "    'MOMENTUM': 0.9,\n",
    "    'DATASET_NAME':'mnist',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'model',\n",
       " 'utils',\n",
       " 'LICENSE',\n",
       " '.gitignore',\n",
       " '.git',\n",
       " 'Capsule Network Train.ipynb',\n",
       " 'Pretrain_Capsule.ipynb',\n",
       " 'L2_recon.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'README.md',\n",
       " 'CapsNetMNIS.pth ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modified Decoder\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_width=28, input_height=28, input_channel=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.input_channel = input_channel\n",
    "        self.reconstraction_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, self.input_height * self.input_height * self.input_channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes.squeeze(), dim=1)\n",
    "\n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = torch.sparse.torch.eye(10)\n",
    "        if USE_CUDA:\n",
    "            masked = masked.cuda()\n",
    "        masked = masked.index_select(dim=0, index=max_length_indices.squeeze().data)\n",
    "#         t = (x * masked[:, :, None, None]).view(x.size(0), -1)\n",
    "        reconstructions = self.reconstraction_layers(x)\n",
    "        reconstructions = reconstructions.view(-1, self.input_channel, self.input_width, self.input_height)\n",
    "        return reconstructions, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Config for 49 16d vectors in the Primary Capsule. Set Softmax dimension to 0 in this case\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # CNN (cnn)\n",
    "        self.cnn_in_channels = 1\n",
    "        self.cnn_out_channels = 12\n",
    "        self.cnn_kernel_size = 15\n",
    "\n",
    "        # Primary Capsule (pc)\n",
    "        self.pc_num_capsules = 16\n",
    "        self.pc_in_channels = 12\n",
    "        self.pc_out_channels = 1\n",
    "        self.pc_kernel_size = 8\n",
    "        self.pc_num_routes = 1 * 7 * 7\n",
    "\n",
    "        # Digit Capsule 1 (dc)\n",
    "        self.dc_num_capsules = 49\n",
    "        self.dc_num_routes = 1 * 7 * 7\n",
    "        self.dc_in_channels = 16\n",
    "        self.dc_out_channels = 16\n",
    "        \n",
    "        # Digit Capsule 2 (dc)\n",
    "        self.dc_2_num_capsules = 10\n",
    "        self.dc_2_num_routes = 1 * 7 * 7\n",
    "        self.dc_2_in_channels = 16\n",
    "        self.dc_2_out_channels = 16\n",
    "\n",
    "        # Decoder\n",
    "        self.input_width = 28\n",
    "        self.input_height = 28\n",
    "\n",
    "torch.manual_seed(1)\n",
    "config = Config()\n",
    "\n",
    "net = CapsNet(config)\n",
    "# capsule_net = torch.nn.DataParallel(capsule_net)\n",
    "if args['USE_CUDA']:\n",
    "    net = net.cuda()\n",
    "    \n",
    "net.load_state_dict(torch.load(os.path.join(model_path, 'CapsNetMNIST.pth'), map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = dataset(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The histogram of L2 distances between the input and the reconstruction using the\n",
    "## correct capsule or other capsules in CapsNet on the real MNIST images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(capsule_net.state_dict(), \"./CapsNetMNIST.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config for 16 1d vectors in Capsule Layer. Set the Softmax Dimension to 1 in this case\n",
    "# class Config:\n",
    "#     def __init__(self, dataset='mnist'):\n",
    "#         # CNN (cnn)\n",
    "#         self.cnn_in_channels = 1\n",
    "#         self.cnn_out_channels = 12\n",
    "#         self.cnn_kernel_size = 15\n",
    "\n",
    "#         # Primary Capsule (pc)\n",
    "#         self.pc_num_capsules = 1\n",
    "#         self.pc_in_channels = 12\n",
    "#         self.pc_out_channels = 16\n",
    "#         self.pc_kernel_size = 8\n",
    "#         self.pc_num_routes = 16 * 7 * 7\n",
    "\n",
    "#         # Digit Capsule 1 (dc)\n",
    "#         self.dc_num_capsules = 49\n",
    "#         self.dc_num_routes = 16 * 7 * 7\n",
    "#         self.dc_in_channels = 1\n",
    "#         self.dc_out_channels = 1 #16\n",
    "        \n",
    "#         # Digit Capsule 2 (dc)\n",
    "#         self.dc_2_num_capsules = 10\n",
    "#         self.dc_2_num_routes = 7 * 7\n",
    "#         self.dc_2_in_channels = 1 #16\n",
    "#         self.dc_2_out_channels = 16\n",
    "\n",
    "#         # Decoder\n",
    "#         self.input_width = 28\n",
    "#         self.input_height = 28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
